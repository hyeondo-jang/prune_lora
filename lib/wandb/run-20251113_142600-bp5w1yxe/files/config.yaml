'?':
    value: false
_wandb:
    value:
        cli_version: 0.19.11
        m: []
        python_version: 3.10.18
        t:
            "1":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 51
                - 53
                - 55
                - 71
                - 98
                - 100
            "2":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 51
                - 53
                - 55
                - 71
                - 98
                - 100
            "3":
                - 23
                - 55
                - 61
            "4": 3.10.18
            "5": 0.19.11
            "6": 4.45.0
            "8":
                - 5
            "12": 0.19.11
            "13": linux-x86_64
actual_effective_batch_size:
    value: 8
alsologtostderr:
    value: false
batch_size:
    value: 8
block_size:
    value: 2048
config_name:
    value: facebook/opt-125m
data_path:
    value: null
dataset_name:
    value: c4
do_eval:
    value: true
do_train:
    value: true
eval_samples:
    value: 4
eval_steps:
    value: 1
eval_zero_shot:
    value: true
gradient_accumulation_steps:
    value: 1
help:
    value: false
helpfull:
    value: false
helpshort:
    value: false
helpxml:
    value: false
learning_rate:
    value: 0.0001
log_dir:
    value: ""
logging_steps:
    value: 1
logtostderr:
    value: false
lora_alpha:
    value: 16
lora_dropout:
    value: 0.05
lora_r:
    value: 8
lr_scheduler_type:
    value: linear
model_name_or_path:
    value: /home/hyeondojang/log_teams/opt-model/elsa_iclr26/save/Llama-2-7b-hf_wanda/0.6
num_gpus:
    value: 1
num_train_epochs:
    value: 1
only_check_args:
    value: false
output_dir:
    value: ./lora_ft_output
overwrite_output_dir:
    value: true
pdb:
    value: false
pdb_post_mortem:
    value: false
per_device_eval_batch_size:
    value: 1
per_device_train_batch_size:
    value: 8
profile_file:
    value: null
requested_batch_size:
    value: 8
run_with_pdb:
    value: false
run_with_profiling:
    value: false
seed:
    value: 0
showprefixforinfo:
    value: true
stderrthreshold:
    value: fatal
steps:
    value: 8
train_samples:
    value: 64
use_cprofile_for_profiling:
    value: true
v:
    value: 0
verbosity:
    value: 0
wandb:
    value: true
wandb_project:
    value: test
warmup_steps:
    value: 0
